{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Core\n",
    "In this notebook we are going to explore the following topics:  \n",
    "\n",
    "- Introduction to Ray system architecture;\n",
    "- Connecting to a Ray Cluster;\n",
    "- Ray tasks and actors;\n",
    "- The object storage;\n",
    "- Specifying resources usage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ray Architecture\n",
    "A Ray cluster is made by the following components\n",
    "- A single **head node**.\n",
    "- Zero or more **worker nodes**.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/ray-cluster.svg\" alt=\"Structure of a Ray Cluster\" style=\"width:50%;\">\n",
    "</div>\n",
    "\n",
    "The **head node is a special cluster node**, which, additionally to worker processes, hosts processes responsible for cluster management (mainly the GCS, the Ray Autoscaler). Usually the Ray driver process, which is the program responsible to submit jobs, is run on the Ray head node, but it can also run on another computer, and connect to a remote cluster.  \n",
    "The **GCS** (Global Control Service) is a service used for monitoring resource availability and to dispatch changes to other workers. The GCS is also used to save remote function definitions.  \n",
    "\n",
    "The **worker nodes** are regular nodes which do not run any cluster management process. These nodes simply contribute to the cluster by sharing their resources (CPUs, RAM, and GPUs) that will be used to execute the jobs. It is important to note that each node has a **scheduler** and an **object store**.  \n",
    "The nodes schedulers are used to schedule tasks and to evaluate if a worker has enough resources to execute a task. Similarly, the workers have an object store that is used to save intermediate results (i.e. variables and objects) to be used later. In case a node has no computing resources available but owns the data needed to execute the task, the data used will be serialized and sent to the worker node that was selected to execute the job.  \n",
    "\n",
    "For a detailed and rich description of Ray architecture, consider reading [this](https://docs.daocloud.io/en/blogs/2023/230612-ray)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to a Ray cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/leonardo_work/tra26_castiel2/mviscia1/ray_rag_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2026-01-29 08:02:12,109\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import ray\n",
    "from ray.util.actor_pool import ActorPool\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already started our Ray cluster on Leonardo by running the jobscript `start_ray_interactive.sh`. We can now connect to it using ray.init() (since we have exported the environment variable RAY_ADDRESS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 08:04:01,966\tINFO worker.py:1520 -- Using address 10.11.1.34:23707 set in the environment variable RAY_ADDRESS\n",
      "2026-01-29 08:04:01,966\tINFO worker.py:1660 -- Connecting to existing Ray cluster at address: 10.11.1.34:23707...\n",
      "2026-01-29 08:04:01,975\tINFO worker.py:1843 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32mhttp://10.11.1.34:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m WARNING: 32 PYTHON worker processes have been started on node: e53d35741c422e42b46106fa2989b8cda066fe1f3215f34430a55237 with address: 10.11.1.34. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n"
     ]
    }
   ],
   "source": [
    "ray.init(log_to_driver = False, ignore_reinit_error = True)\n",
    "\n",
    "#os.environ[\"HF_HOME\"]=\"/leonardo_scratch/fast/tra25_bbs/rmioli00/models/hub\"\n",
    "#os.environ[\"HF_HUB_CACHE\"]=\"/leonardo_scratch/fast/tra25_bbs/rmioli00/models/hub\"\n",
    "os.environ[\"HF_OFFLINE\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Ray cluster we have various types of resources:\n",
    "- CPUs;\n",
    "- GPUs;\n",
    "- Memory (\"execution memory\" and object store memory).\n",
    "\n",
    "The difference between memory and object store memory is that the first one is the memory used by the workers during the execution of remote functions, datasets, etc; on the opposite, the object store memory is memory reserved to share objects between workers and to save \"intermediate results\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster has 8.0 CPUs, 1.0 GPUs, execution memory 361.684707328 GBs, object storage memory 155.007731712 GBs\n"
     ]
    }
   ],
   "source": [
    "resources = ray.cluster_resources()\n",
    "print(f\"Cluster has {resources['CPU']} CPUs, {resources['GPU'] if 'GPU' in resources else 0} GPUs, execution memory {resources['memory'] * 1e-9} GBs, object storage memory {resources['object_store_memory'] * 1e-9} GBs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Core - Tasks, Actors and Objects\n",
    "A program using Ray is called a job. In a job you usually make various operations (e.g. reading datasets, manipulating columns, training classifiers, etc), so this jobs are composed by \"subtasks\". To accomplish the work, Ray offers two basic components: **tasks and actors**\n",
    "\n",
    "## A serial workflow\n",
    "Suppose we have built a website or some sort of a platform that needs to retrieve user data and then, when all data is loaded, it greets the user. We can simulate five users logging to this website using the following function.  \n",
    "The users are served sequentially, but this represents a bottleneck due to the fact that the data retrival happens using a FIFO queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome back, Domitilla! Your data was successfully loaded.\n",
      "Welcome back, Eleonora! Your data was successfully loaded.\n",
      "Welcome back, Laura! Your data was successfully loaded.\n",
      "Welcome back, Michele! Your data was successfully loaded.\n",
      "Welcome back, Riccardo! Your data was successfully loaded.\n",
      "CPU times: user 13.3 ms, sys: 3.51 ms, total: 16.8 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def load_people_data(name:str):\n",
    "    time.sleep(2) # We simulate a very long operation on a database\n",
    "    return f\"Welcome back, {name}! Your data was successfully loaded.\"\n",
    "\n",
    "names = [\"Domitilla\", \"Eleonora\", \"Laura\", \"Michele\", \"Riccardo\"]\n",
    "for name in names:\n",
    "    print(load_people_data(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Tasks\n",
    "We now define the same function, but we parallelize its execution with Ray Tasks. Ray can execute the user defined function in parallel by sending a copy of it to each worker process. The remote function will be then executed receiving as input the names of the users.  \n",
    "\n",
    "Functions using the `@ray.remote` decorator are called Ray remote functions and their execution is called a Ray Tasks. It's important to note that **tasks are stateless**, which means that once a task is executed, the only thing that is saved is the output of the function in the object storage of the worker that executed the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectRef(67a2e8cfa5a06db3ffffffffffffffffffffffff0200000001000000)\n",
      "ObjectRef(e082c90ab8422b00ffffffffffffffffffffffff0200000001000000)\n",
      "ObjectRef(e5cbd90b7f1fb776ffffffffffffffffffffffff0200000001000000)\n",
      "ObjectRef(39088be3736e590affffffffffffffffffffffff0200000001000000)\n",
      "ObjectRef(ce868e48e2fa9a94ffffffffffffffffffffffff0200000001000000)\n",
      "CPU times: user 26.1 ms, sys: 8.56 ms, total: 34.7 ms\n",
      "Wall time: 52.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "@ray.remote\n",
    "def load_people_data(name:str):\n",
    "    time.sleep(2) # We simulate a very long operation on a database\n",
    "    return f\"Welcome back, {name}! Your data was successfully loaded.\"\n",
    "\n",
    "for name in names:\n",
    "    print(load_people_data.remote(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the execution time is on the order of milliseconds, which is obviously much less than the initial 10 seconds. Even if we had run the function in parallel, we couldn't have retrieved the data for all the users in less than 10 seconds due to the `time.sleep(2)`!  \n",
    "What you have observed is called **asynchronous execution**. When you call a remote function, its execution is scheduled on some worker node and a \"promise\" (the Ray `ObjectRef`), an ID of the operations' reuslt, is immediatly returned to the caller.  \n",
    "To get the actual results we can use `ray.get()` on the IDs of the results. Note that `ray.get()` on Ray task results will block until the task finished execution. For example, if you want to schedule the execution of tasks while waiting for some of them to finish, or if you want to monitor intermediate results of different computations and make a plot, you can use `ray.wait()`. `ray.wait()` returns two lists: list of completed ObjectRefs and list of not ready ObjectRefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome back, Eleonora! Your data was successfully loaded.']\n",
      "['Welcome back, Domitilla! Your data was successfully loaded.']\n",
      "['Welcome back, Laura! Your data was successfully loaded.']\n",
      "['Welcome back, Michele! Your data was successfully loaded.']\n",
      "['Welcome back, Riccardo! Your data was successfully loaded.']\n",
      "CPU times: user 12.6 ms, sys: 6.8 ms, total: 19.4 ms\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "refs = [load_people_data.remote(name) for name in names]\n",
    "\n",
    "while len(refs) > 0:\n",
    "    finished, refs = ray.wait(refs)\n",
    "    print(ray.get(finished))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Actors\n",
    "\n",
    "Let's now suppose we want to keep track of the number of times a user has logged into the website.\n",
    "\n",
    "Tasks are stateless, to overcome this issue, we have actors. Actors are Python classes decorated with `@ray.remote`, when we call `ClassName.remote()` the actor is scheduled on some worker and the `__init__` function is executed to instantiate the actor. Then **we can maintain state using actor's instance variables**.  \n",
    "This is also useful if the class has a long initialization tasks that must be performed once; for example, loading llm weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class FakeDB():\n",
    "    def __init__(self, db_backend:str=\"MySQL\", server_id:int=0):\n",
    "        self.access_no = {}\n",
    "        self.db_backend = db_backend\n",
    "        self.server_id = server_id\n",
    "        \n",
    "    def load_people_data(self, name:str):\n",
    "        time.sleep(2) # We simulate a very long operation on a database\n",
    "        if name in self.access_no:\n",
    "            self.access_no[name] +=1\n",
    "        else:\n",
    "            self.access_no[name] = 1\n",
    "        return f\"Welcome back, {name}! Your data was successfully loaded from {self.db_backend}_{self.server_id}. Today you logged in {self.access_no[name]} times.\"\n",
    "    \n",
    "db_actor = FakeDB.remote(db_backend = \"mongodb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can launch the task on the actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ObjectRef(4e42fef2e4fc2164e161e609afab3c6efb57ed330200000001000000), ObjectRef(a634bb3b3ca530f0e161e609afab3c6efb57ed330200000001000000), ObjectRef(d10410bd3222d6a4e161e609afab3c6efb57ed330200000001000000), ObjectRef(ca701c49794a1d14e161e609afab3c6efb57ed330200000001000000), ObjectRef(dd09e9796bb10db3e161e609afab3c6efb57ed330200000001000000)]\n",
      "['Welcome back, Domitilla! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "['Welcome back, Eleonora! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "['Welcome back, Laura! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "['Welcome back, Michele! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "['Welcome back, Riccardo! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "CPU times: user 15 ms, sys: 4.89 ms, total: 19.9 ms\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "refs = [db_actor.load_people_data.remote(name) for name in names]\n",
    "print(refs)\n",
    "\n",
    "while len(refs) > 0:\n",
    "    finished, refs = ray.wait(refs)\n",
    "    print(ray.get(finished))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the object refs were immediatly returned (i.e. the tasks were scheduled), but the actual execution required much more time.\n",
    "In this case, having a single actor constitutes a bottleneck because when the actor is executing the code for an user it's \"busy\" and we can't serve another user. However, this is the intended expected behaviour, and it's because actors functions by default are single threaded.\n",
    "To overcome this issue we can create different actors, the methods called on the different actors will execute in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome back, Domitilla! Your data was successfully loaded from mongodb_4. Today you logged in 1 times.', 'Welcome back, Eleonora! Your data was successfully loaded from mongodb_3. Today you logged in 1 times.', 'Welcome back, Laura! Your data was successfully loaded from mongodb_2. Today you logged in 1 times.', 'Welcome back, Michele! Your data was successfully loaded from mongodb_1. Today you logged in 1 times.', 'Welcome back, Riccardo! Your data was successfully loaded from mongodb_0. Today you logged in 1 times.']\n",
      "CPU times: user 8.82 ms, sys: 7.19 ms, total: 16 ms\n",
      "Wall time: 2.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "actor_pool = ActorPool([FakeDB.remote(db_backend = \"mongodb\", server_id = i) for i in range(5)])\n",
    "\n",
    "# We map each actor to a value\n",
    "mapped_jobs = actor_pool.map(lambda actor, value: actor.load_people_data.remote(value), names)\n",
    "\n",
    "print(list(mapped_jobs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object storage\n",
    "The distributed object storage is the sum of the portions of memory of the workers dedicated to save intermediate results originating from the executions of tasks and actors. By default, the **30% of the memory of a worker** will be used as object storage. When the space of the object storage finishes, the data in will be spilled to disk.  \n",
    "\n",
    "The user can interact with the object storage with two commands:  \n",
    "- `ray.put`: save data in some worker's memory;\n",
    "- `ray.get`: retrieve data associated to an `ObjectRef` (Ray solves which workers has this data automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ObjectRef(00ffffffffffffffffffffffffffffffffffffff0200000001e1f505)\n"
     ]
    }
   ],
   "source": [
    "api_key = \"EXAMPLE_0af8791jd91j651hgjalmnc\"\n",
    "\n",
    "key_ref = ray.put(api_key)\n",
    "print(key_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE_0af8791jd91j651hgjalmnc\n"
     ]
    }
   ],
   "source": [
    "print(ray.get(key_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class APIHelper():\n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        \n",
    "    def call_endpoint(self):\n",
    "        import random\n",
    "        \n",
    "        time.sleep(2)\n",
    "        return f\"Authentication succeded using {self.api_key}. Server returned {random.randint(0, 1)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an `ObjectRef` is passed as input to tasks or actors, Ray will call automatically the `.get` method.\n",
    "api_actor = APIHelper.remote(key_ref)\n",
    "ray.get(api_actor.call_endpoint.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Authentication succeded using EXAMPLE_0af8791jd91j651hgjalmnc. Server returned 1'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_actor = APIHelper.remote(key_ref)\n",
    "ray.get(api_actor.call_endpoint.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying resources for Tasks and Actors\n",
    "\n",
    "When defining tasks and actors in Ray, **you can specify the resources** required for their execution. The Ray scheduler uses this information to determine which worker node is suitable for running the task.\n",
    "This feature is particularly useful as it provides a high-level yet powerful **mechanism to control resource allocation**. It helps prevent issues such as crashes due to out-of-memory (OOM) errors by ensuring tasks are only assigned to nodes with sufficient resources.\n",
    "\n",
    "Here is an example: Suppose you have a cluster with 16 GB per GPU and you want to execute several LLMs (each using 8 GB of GPU memory). You can instantiate actors by specifying that they must use 0.5 GPUs. This will ensure that a maximum of two LLM actors are executed per node.\n",
    "Similarly, if you have functions that require a certain amount of memory and CPU cores to execute, you can specify them in the same way. These tasks can be scheduled on the same nodes that execute LLM actors, because LLM actors only use GPU resources and CPU cores and memory are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Even if num_cpus is 2, the task sees 8.0 CPUs. Resources are logical!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two cpu cores, and 500MiB of RAM\n",
    "@ray.remote(num_cpus = 2, memory=500 * 1024 * 1024)\n",
    "def example_task():\n",
    "    import os\n",
    "    \n",
    "    return f\"Even if num_cpus is 2, the task sees {resources['CPU']} CPUs. Resources are logical!\"\n",
    "\n",
    "ray.get(example_task.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important note is that **Ray resources are \"logical\"**, meaning that the number of CPU cores, or GPUs specified are not enforced by Ray.  \n",
    "Going back to the previous example, if the GPU memory occupied by the LLMs is greater than 8GB, specifiying that each actor must use 0.5 GPUs will not be beneficial because two actors will be scheduled on the workers, incurring in an OOM error.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "- What happens if you set `num_gpus = 3` to the previous `example_task` function? Can you explain why?\n",
    "- What happens if you set `num_cpus = 5` to the task `load_people_data`? Can you explain why?\n",
    "- Create a calculator actor which supports addition and subtraction operations between two operands. The calculator needs to support a history of the results and a way to retrieve the last three calculations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=0, num_gpus=0.05)\n",
    "class Embedder():\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    def __init__(self, model_name:str = \"/leonardo_scratch/fast/tra26_castiel2/models/all-mpnet-base-v2\"):\n",
    "        self.embedder = SentenceTransformer(model_name)\n",
    "        \n",
    "    def __call__(self, input_path:str):\n",
    "        # Read the txt file associated to the canto\n",
    "        with open(input_path, mode=\"r\") as f:\n",
    "            data = f.read()\n",
    "            \n",
    "        # Extract the number of the canto    \n",
    "        canto = int(input_path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "        \n",
    "        # Calculate the embeddings\n",
    "        embeddings = self.embedder.encode([data])[0].tolist()\n",
    "        # Return a tuple with the number of the canto and the embeddings\n",
    "        return_dict = {\"canto\": canto }\n",
    "        for i in range(len(embeddings)):\n",
    "            return_dict[f\"{i}\"] = embeddings[i]\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a bunch of files, which contain the full Dante's Divine Comedy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/leonardo_scratch/fast/tra26_castiel2/mviscia1/data/ray_core/canto_81.txt',\n",
       " '/leonardo_scratch/fast/tra26_castiel2/mviscia1/data/ray_core/canto_71.txt',\n",
       " '/leonardo_scratch/fast/tra26_castiel2/mviscia1/data/ray_core/canto_86.txt',\n",
       " '/leonardo_scratch/fast/tra26_castiel2/mviscia1/data/ray_core/canto_60.txt',\n",
       " '/leonardo_scratch/fast/tra26_castiel2/mviscia1/data/ray_core/canto_56.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob(\"/leonardo_scratch/fast/tra26_castiel2/data/ray_core/*\")\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create an ActorPool with 10 embedders. We could create more than 10, but we set num_gpus 0.10 and we have only one GPU in this job.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.actor_pool import ActorPool\n",
    "\n",
    "# We instantiate 20 actors - always check the number of actors you schedule fit on the available gpu memory\n",
    "actor_pool = ActorPool([Embedder.remote() for _ in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = actor_pool.map(lambda actor, path: actor.__call__.remote(path), files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 32.7 ms, total: 142 ms\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canto</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>-0.013673</td>\n",
       "      <td>-0.042178</td>\n",
       "      <td>0.020039</td>\n",
       "      <td>-0.012347</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>-0.047387</td>\n",
       "      <td>0.033142</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064089</td>\n",
       "      <td>-0.014925</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>-0.022937</td>\n",
       "      <td>-0.045240</td>\n",
       "      <td>0.069715</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.071358</td>\n",
       "      <td>-0.037445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.020545</td>\n",
       "      <td>-0.035634</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>-0.014652</td>\n",
       "      <td>0.030680</td>\n",
       "      <td>-0.046138</td>\n",
       "      <td>0.067697</td>\n",
       "      <td>-0.007474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020258</td>\n",
       "      <td>0.030111</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>-0.022194</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>-0.009550</td>\n",
       "      <td>0.030902</td>\n",
       "      <td>0.055947</td>\n",
       "      <td>-0.047270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0.022221</td>\n",
       "      <td>0.018050</td>\n",
       "      <td>-0.022917</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>-0.065609</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>-0.023134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059692</td>\n",
       "      <td>-0.006871</td>\n",
       "      <td>-0.001749</td>\n",
       "      <td>-0.017815</td>\n",
       "      <td>-0.019615</td>\n",
       "      <td>0.031071</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.025230</td>\n",
       "      <td>0.038682</td>\n",
       "      <td>-0.024533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>-0.051991</td>\n",
       "      <td>-0.022669</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>-0.003718</td>\n",
       "      <td>0.031651</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.032315</td>\n",
       "      <td>-0.020957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055458</td>\n",
       "      <td>-0.006090</td>\n",
       "      <td>-0.020694</td>\n",
       "      <td>-0.003623</td>\n",
       "      <td>-0.041768</td>\n",
       "      <td>-0.014294</td>\n",
       "      <td>-0.023965</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>-0.056352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>-0.032619</td>\n",
       "      <td>-0.012547</td>\n",
       "      <td>0.008214</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.042901</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>-0.012052</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039766</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.030155</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>-0.032736</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>-0.005280</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>0.051874</td>\n",
       "      <td>-0.025414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>-0.029875</td>\n",
       "      <td>-0.030824</td>\n",
       "      <td>-0.024022</td>\n",
       "      <td>-0.003487</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.033106</td>\n",
       "      <td>-0.024023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074173</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>-0.013067</td>\n",
       "      <td>0.013031</td>\n",
       "      <td>-0.024527</td>\n",
       "      <td>0.022993</td>\n",
       "      <td>-0.015042</td>\n",
       "      <td>0.023245</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>-0.034723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>92</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>-0.013663</td>\n",
       "      <td>-0.023569</td>\n",
       "      <td>0.030094</td>\n",
       "      <td>-0.014003</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>-0.045003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044722</td>\n",
       "      <td>-0.006877</td>\n",
       "      <td>0.042726</td>\n",
       "      <td>-0.033205</td>\n",
       "      <td>-0.042823</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.025191</td>\n",
       "      <td>0.020137</td>\n",
       "      <td>-0.027508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.007506</td>\n",
       "      <td>0.034004</td>\n",
       "      <td>-0.024442</td>\n",
       "      <td>-0.032003</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.027168</td>\n",
       "      <td>-0.022948</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>-0.019632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024906</td>\n",
       "      <td>0.007345</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>-0.021256</td>\n",
       "      <td>0.007798</td>\n",
       "      <td>-0.045879</td>\n",
       "      <td>0.020427</td>\n",
       "      <td>0.028602</td>\n",
       "      <td>-0.029445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>35</td>\n",
       "      <td>0.018430</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>-0.034403</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.014304</td>\n",
       "      <td>-0.037441</td>\n",
       "      <td>0.014420</td>\n",
       "      <td>-0.071528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055584</td>\n",
       "      <td>-0.014020</td>\n",
       "      <td>-0.013413</td>\n",
       "      <td>-0.006020</td>\n",
       "      <td>-0.033642</td>\n",
       "      <td>0.015155</td>\n",
       "      <td>-0.012674</td>\n",
       "      <td>0.021981</td>\n",
       "      <td>0.020901</td>\n",
       "      <td>-0.039151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>94</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.015439</td>\n",
       "      <td>-0.034840</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.018285</td>\n",
       "      <td>0.024491</td>\n",
       "      <td>-0.026345</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>-0.034931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032041</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>-0.042690</td>\n",
       "      <td>-0.038720</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>-0.015520</td>\n",
       "      <td>0.013296</td>\n",
       "      <td>0.025424</td>\n",
       "      <td>-0.027422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    canto         0         1         2         3         4         5  \\\n",
       "0      81 -0.000924 -0.013673 -0.042178  0.020039 -0.012347  0.008459   \n",
       "1      71  0.016341  0.020545 -0.035634  0.000869 -0.014652  0.030680   \n",
       "2      86  0.022221  0.018050 -0.022917  0.034534 -0.004871  0.025595   \n",
       "3      60  0.014424 -0.051991 -0.022669  0.003660 -0.003718  0.031651   \n",
       "4      56  0.018417 -0.032619 -0.012547  0.008214  0.014980  0.042901   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "95      8  0.005598 -0.029875 -0.030824 -0.024022 -0.003487  0.011112   \n",
       "96     92  0.018613 -0.013663 -0.023569  0.030094 -0.014003  0.024391   \n",
       "97      2 -0.007506  0.034004 -0.024442 -0.032003  0.000467  0.027168   \n",
       "98     35  0.018430  0.016690 -0.034403  0.001225  0.006255  0.014304   \n",
       "99     94  0.021218  0.015439 -0.034840 -0.001295  0.018285  0.024491   \n",
       "\n",
       "           6         7         8  ...       758       759       760       761  \\\n",
       "0  -0.047387  0.033142 -0.020576  ... -0.064089 -0.014925  0.020101 -0.022937   \n",
       "1  -0.046138  0.067697 -0.007474  ... -0.020258  0.030111 -0.001424 -0.022194   \n",
       "2  -0.065609  0.037637 -0.023134  ... -0.059692 -0.006871 -0.001749 -0.017815   \n",
       "3   0.004777  0.032315 -0.020957  ... -0.055458 -0.006090 -0.020694 -0.003623   \n",
       "4  -0.014164  0.053587 -0.012052  ... -0.039766  0.021823  0.030155 -0.004375   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95  0.008071  0.033106 -0.024023  ... -0.074173  0.004086 -0.013067  0.013031   \n",
       "96 -0.020590  0.022258 -0.045003  ... -0.044722 -0.006877  0.042726 -0.033205   \n",
       "97 -0.022948  0.056362 -0.019632  ... -0.024906  0.007345  0.000835 -0.006021   \n",
       "98 -0.037441  0.014420 -0.071528  ... -0.055584 -0.014020 -0.013413 -0.006020   \n",
       "99 -0.026345  0.038699 -0.034931  ... -0.032041  0.024194  0.028006 -0.042690   \n",
       "\n",
       "         762       763       764       765       766       767  \n",
       "0  -0.045240  0.069715 -0.009456  0.010452  0.071358 -0.037445  \n",
       "1   0.000098  0.003161 -0.009550  0.030902  0.055947 -0.047270  \n",
       "2  -0.019615  0.031071 -0.034607  0.025230  0.038682 -0.024533  \n",
       "3  -0.041768 -0.014294 -0.023965  0.041703  0.002475 -0.056352  \n",
       "4  -0.032736  0.008290 -0.005280  0.035342  0.051874 -0.025414  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.024527  0.022993 -0.015042  0.023245  0.020135 -0.034723  \n",
       "96 -0.042823  0.045139  0.002348  0.025191  0.020137 -0.027508  \n",
       "97 -0.021256  0.007798 -0.045879  0.020427  0.028602 -0.029445  \n",
       "98 -0.033642  0.015155 -0.012674  0.021981  0.020901 -0.039151  \n",
       "99 -0.038720  0.015914 -0.015520  0.013296  0.025424 -0.027422  \n",
       "\n",
       "[100 rows x 769 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
