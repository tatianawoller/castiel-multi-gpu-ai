{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02aad13-b697-488f-9d36-8dfc661bcaef",
   "metadata": {},
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12980a30-7bb9-4d65-a8a8-ed9cf030ee86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BNB_CUDA_VERSION'] = '120'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4d441-b5af-40fe-b4c8-a52db0301f0c",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3ace45-34f6-4815-8836-f36d57c02afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(example):\n",
    "    return f'### Question: {example[\"input\"]}\\n### Answer: {example[\"output\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ca8e794-5600-446c-98d3-f08343b0578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b74a22-8ba4-488b-abe0-bd36aaee672d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95054e278a114628bbf3304e6ebd1ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files='pandas_data_analysis_questions_train.jsonl',\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5484eb3c-1446-418e-accc-a1704e6fb263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12ee3c91bc54a87a1c027bc3409e895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_dataset = load_dataset(\n",
    "    'json',\n",
    "    data_files='pandas_data_analysis_questions_test.jsonl',\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff74e1-bd9f-44bf-8269-6479bdf81b05",
   "metadata": {},
   "source": [
    "## Log in to Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1c92cb-421a-45d3-861d-06b75b844320",
   "metadata": {},
   "source": [
    "To access models from Hugging Space you need to login. This requires an access token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae31e47-9094-4857-a908-cd1b8e2bb0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e1ec6fafce44b2aa66a6162d5bb410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login(new_session=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd031e81-6606-477e-bf11-b3d58572456f",
   "metadata": {},
   "source": [
    "## Configure and download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ad589b1-e51e-46d2-825c-498339b7f021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6ef7fe052e4e66a4f38f7d74cbdc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772ae03e-a556-4176-aafd-cafc352b31de",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0494af9-2c72-4306-add4-206a326171df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786b52f325854ed08569e622df2c0808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: BNB_CUDA_VERSION=120 environment variable detected; loading libbitsandbytes_cuda120.so.\n",
      "This can be used to load a bitsandbytes version that is different from the PyTorch CUDA version.\n",
      "If this was unintended set the BNB_CUDA_VERSION variable to an empty string: export BNB_CUDA_VERSION=\n",
      "If you use the manual override make sure the right libcudart.so is in your LD_LIBRARY_PATH\n",
      "For example by adding the following to your .bashrc: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:<path_to_cuda_dir/lib64\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de4399ceace481e86a29c70659a44f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3d9a65a2ae461bbb94617ccb49ef7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193858eca64f4365aa89f5c955a1b618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc95fdd723684ad48578abbc8a950c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b9362d058f4fc2b0c276c8152574fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823de2bc99374696a62a9df77fe75aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f43fd5-232b-4ecb-a995-77f313b5c8f2",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750f2fd-b15d-428f-b1b3-8ae8a7d227ee",
   "metadata": {},
   "source": [
    "The maximum number of tokens for the input is 200, hence this is used for padding.  Special tokens are added at the start and end of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dada309-138a-4342-81ed-0bbbf4891c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2d746cc63f4212978e91e5c961ccc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671269c325934389965c4cf764b3a5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d82b0c8a4f84885955de5a2e24098df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5b04d1707e44d29ed9e86c7e976b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True,\n",
    "    add_bos_token=True,\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd38571d-6bc1-4901-bc9f-8b8074bb6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(prompt):\n",
    "    return tokenizer(\n",
    "        format_prompt(prompt),\n",
    "        max_length=200,\n",
    "        padding=\"max_length\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bec14f8-bcbf-4e67-8cd1-59c555ce48d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c332e46b690409890db7f29b2b1cc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3628 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7e13cbbac35408682103ca42dd1be9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_test_dataset = test_dataset.map(generate_and_tokenize_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb0b5dac-de7b-4cdc-9396-b7b6e378e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
    "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2082784-c057-4601-8ad1-a8e5019672fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_data_lengths(tokenized_train_dataset, tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7cfec-2291-47ff-a4f8-b74681b992e6",
   "metadata": {},
   "source": [
    "## Base model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82438265-b721-4323-b3d6-a7dca2892384",
   "metadata": {},
   "source": [
    "To check the performance of the model as is, i.e., without fine-tuning, we can provide a prompt and see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abbb1e5e-7672-4f61-a87b-5a56f7fcd777",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = \"How to concatenate two dataframes along rows?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20550c4c-aa2b-48f5-b04a-76cd954a2639",
   "metadata": {},
   "source": [
    "Get the tokenizer for the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a62ba7ab-dac4-4e04-ae2b-8ac5574505a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341cd676-0d14-49ec-a281-581e9938757d",
   "metadata": {},
   "source": [
    "Tokenize the evaluation prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d084bf-4790-4da6-8004-878473b54dd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_input = evaluation_tokenizer(\n",
    "    evaluation_prompt,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e16f18f-e840-4bfd-babc-0a63992c8425",
   "metadata": {},
   "source": [
    "Put the model in evaluation mode, and infer without keeping track of the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "683bfc2f-2eac-4b8c-be8c-289d272f88b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to concatenate two dataframes along rows?\n",
      "\n",
      "I have a dataframe with 10 columns and 250,000 rows. I want to add another dataframe that has the same number of columns but only 30,000 rows. The result should be a new dataframe with 10 columns and 280,000 rows.\n",
      "\n",
      "How can this be done in pandas?\n",
      "\n",
      "The following code does not work:\n",
      "\n",
      "```\n",
      "df = pd.concat([df1, df2], axis=0)\n",
      "```\n",
      "\n",
      "It gives me an error message saying that the indexes are different.\n",
      "\n",
      "Is there any way to do it without reindexing both dataframes?\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(evaluation_tokenizer.decode(\n",
    "              model.generate(\n",
    "                  **model_input,\n",
    "                  max_new_tokens=256,\n",
    "                  repetition_penalty=1.15)[0],\n",
    "        skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2b058f-18f1-4674-8721-a0b4cc061cd1",
   "metadata": {},
   "source": [
    "The result is relevant, but it is a question, not an answer to our prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945eddb-0159-4437-9c2d-0c47db282a57",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8618e-97ec-439a-9fee-f99526d4c63e",
   "metadata": {},
   "source": [
    "We can visualize the architecture by simply printing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cb8898f-bda0-4d45-aad4-fe15e402dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MistralForCausalLM(\n",
      "  (model): MistralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MistralDecoderLayer(\n",
      "        (self_attn): MistralSdpaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MistralRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): MistralMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f5dfbe-c53e-4e64-96dd-a05f0904b3b6",
   "metadata": {},
   "source": [
    "## PEFT: Parameter-Efficient Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19dbcbd5-855b-4683-a4a2-1cf6c9329ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "kbit_training_model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be928cf3-2d32-4f03-8f5d-7824264044fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "peft_model = get_peft_model(kbit_training_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4554fc4-9cbe-4c74-b8a7-48aaffd50fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d7bfbc2-2d40-4e30-96c9-88df3747a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.22\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c21baf-0316-4c92-9cbf-ca1a9b80062c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): MistralForCausalLM(\n",
      "      (model): MistralModel(\n",
      "        (embed_tokens): Embedding(32000, 4096)\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x MistralDecoderLayer(\n",
      "            (self_attn): MistralSdpaAttention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): MistralRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): MistralMLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=14336, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=14336, out_features=32, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "            (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
      "      )\n",
      "      (lm_head): lora.Linear(\n",
      "        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n",
      "        (lora_dropout): ModuleDict(\n",
      "          (default): Dropout(p=0.05, inplace=False)\n",
      "        )\n",
      "        (lora_A): ModuleDict(\n",
      "          (default): Linear(in_features=4096, out_features=32, bias=False)\n",
      "        )\n",
      "        (lora_B): ModuleDict(\n",
      "          (default): Linear(in_features=32, out_features=32000, bias=False)\n",
      "        )\n",
      "        (lora_embedding_A): ParameterDict()\n",
      "        (lora_embedding_B): ParameterDict()\n",
      "        (lora_magnitude_vector): ModuleDict()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e78a6a5c-4474-4c31-ab22-e98663c8d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc32b112-39a3-43d8-9b1c-c5b5bec5417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    peft_model.is_parallelizable = True\n",
    "    peft_model.model_parallel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb5fd18c-32af-4e82-a4f7-4c74e79fe3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d3098d5-9803-4b43-96bf-92c8bed41b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerated_model = accelerator.prepare_model(peft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5b49bbe-5b37-468d-a978-6fe74e6777dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='326' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [326/500 3:15:23 < 1:44:55, 0.03 it/s, Epoch 0.18/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.184677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.128236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.082221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.097600</td>\n",
       "      <td>0.081695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.066059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.062790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.054468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.056787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.049626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.051896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.046977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.045167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.044454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/gjb/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:603] . unexpected pos 130979648 vs 130979536",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/torch/serialization.py:850\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 850\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/torch/serialization.py:1122\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;66;03m# Now that it is on the CPU we can directly copy it into the zip file\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:778] . PytorchStreamWriter failed writing file data/599: file write failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 36\u001b[0m\n\u001b[1;32m     10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m transformers\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39maccelerated_model,\n\u001b[1;32m     12\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_train_dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mtransformers\u001b[38;5;241m.\u001b[39mDataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m accelerated_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# silence the warnings. Please re-enable for inference!\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/trainer.py:3007\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   3004\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate(trial, ignore_keys_for_eval)\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 3007\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/trainer.py:3101\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(output_dir, _internal_call\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_only_model:\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;66;03m# Save optimizer and scheduler\u001b[39;00m\n\u001b[0;32m-> 3101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_optimizer_and_scheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3102\u001b[0m     \u001b[38;5;66;03m# Save RNG state\u001b[39;00m\n\u001b[1;32m   3103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_rng_state(output_dir)\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/transformers/trainer.py:3247\u001b[0m, in \u001b[0;36mTrainer._save_optimizer_and_scheduler\u001b[0;34m(self, output_dir)\u001b[0m\n\u001b[1;32m   3242\u001b[0m     save_fsdp_optimizer(\n\u001b[1;32m   3243\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfsdp_plugin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, output_dir\n\u001b[1;32m   3244\u001b[0m     )\n\u001b[1;32m   3245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   3246\u001b[0m     \u001b[38;5;66;03m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[39;00m\n\u001b[0;32m-> 3247\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOPTIMIZER_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3249\u001b[0m \u001b[38;5;66;03m# Save SCHEDULER & SCALER\u001b[39;00m\n\u001b[1;32m   3250\u001b[0m is_deepspeed_custom_scheduler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_deepspeed_enabled \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   3251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler, DeepSpeedSchedulerWrapper\n\u001b[1;32m   3252\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/torch/serialization.py:849\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    846\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    850\u001b[0m         _save(\n\u001b[1;32m    851\u001b[0m             obj,\n\u001b[1;32m    852\u001b[0m             opened_zipfile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    855\u001b[0m             _disable_byteorder_record,\n\u001b[1;32m    856\u001b[0m         )\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/ai_tools_fine_tuning/lib/python3.12/site-packages/torch/serialization.py:690\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_stream\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:603] . unexpected pos 130979648 vs 130979536"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datetime import datetime\n",
    "\n",
    "project = 'pandas_questions'\n",
    "base_model_name = \"mistral\"\n",
    "run_name = f'{base_model_name}-{project}'\n",
    "output_dir = f'./{run_name}'\n",
    "learning_rate = 2.5e-5\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=accelerated_model,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=2,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=1,\n",
    "        gradient_checkpointing=True,\n",
    "        max_steps=500,\n",
    "        learning_rate=learning_rate,\n",
    "        bf16=True,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_steps=25,              # When to start reporting loss\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=25,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "accelerated_model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc88eba-f6c3-45c9-b84b-2d0a085d698e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
